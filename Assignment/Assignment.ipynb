{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Engineering\n",
    "\n",
    "## Assignment 1<br> Due date:  23/11/16\n",
    "\n",
    "### Author:  134730\n",
    "\n",
    "###### Word count: 1570"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1\\. [Introduction](#chapter-1)<br/>\n",
    "2\\. [Opinion extractor code](#chapter-2)<br/>\n",
    "3\\. [Proof of functionality](#chapter-3)<br/>\n",
    "&nbsp;&nbsp;3.1. [Extension 1](#chapter-3.1)<br/>\n",
    "&nbsp;&nbsp;3.2. [Extension 2](#chapter-3.2)<br/>\n",
    "&nbsp;&nbsp;3.3. [Extension 3](#chapter-3.3)<br/>\n",
    "4\\. [Limitations and real world use](#chapter-4)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction <a id=\"chapter-1\"></a>\n",
    "\n",
    "\n",
    "<p>In this workbook, the writer will be demonstrating an understanding of the Natural Language Engineering (NLE) module to date. This will be accomplished by utilising the Sussex NLTK functions and features, specifically those of the “parse” package.<br/><br/>\n",
    "The main objective of this will be to build an opinion extractor that can gather the opinions of a given topic from a list of pre-parsed sentences built from Amazon DVD reviews. This will be constructed following several “extension” steps outlined in the “Session 8” lab session. These extensions will be used to define the breakdown of the construction and evaluation of the full extractor code.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Opinion Extractor Code <a id=\"chapter-2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def opinion_extractor(aspect_token, parsed_sentence):\n",
    "    \n",
    "    # Your function will have 3 steps:\n",
    "    \n",
    "    # i. Initialise a list of opinions\n",
    "    opinions = []\n",
    "    isNeg = False\n",
    "    \n",
    "    # ii. Find opinions\n",
    "    # check dependants\n",
    "    for dependant in parsed_sentence.get_dependants(aspect_token):\n",
    "        if (dependant.deprel == \"amod\" and dependant.pos == \"JJ\" and not ignoredWord(dependant)):\n",
    "            opinions += enhancedOpinions(dependant, isNeg)\n",
    "        elif (dependant.deprel == \"neg\"):\n",
    "            isNeg = True\n",
    "    # check head (if relevent)\n",
    "    if(aspect_token.deprel == \"nsubj\" or aspect_token.deprel == \"conj\"):\n",
    "        head = parsed_sentence.get_head(aspect_token)\n",
    "        if(not ignoredWord(head)):\n",
    "            if(head.pos == \"JJ\"):\n",
    "                opinions += enhancedOpinions(head, isNeg)\n",
    "            elif(head.deprel == \"nsubj\"):\n",
    "                nextHead = parsed_sentence.get_head(head)\n",
    "                isNeg = False\n",
    "                opinions += enhancedOpinions(nextHead, isNeg)\n",
    "            \n",
    "    # iii. Return the (possibly empty) list of opinions\n",
    "    return opinions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ignoredWord(check): # checks agains a blacklist of words to omit from the results\n",
    "    words = [\"main\",\"special\",\"other\",\"same\",\"at\",\"the\",\"was\",\"have\"] # Blacklisted words\n",
    "    ignore = False\n",
    "    for word in words:\n",
    "        if(check.form == word):\n",
    "            ignore = True\n",
    "    return ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def enhancedOpinions(token, isNeg):\n",
    "    opinionList = []        # List of the actual opinions the extractor cares about\n",
    "    orderList = []          # to keep the ordering of the opinions\n",
    "    opinion = token.form\n",
    "    for dependant in parsed_sentence.get_dependants(token):\n",
    "        if (dependant.deprel == \"advmod\" and not ignoredWord(dependant)): # advmods enhance the value of the opinion\n",
    "            if (dependant.id < token.id):  # checks to see whether the advmod should come before or after the token\n",
    "                opinion = dependant.form + \"-\" + token.form      # adverb + \"-\" + adjective\n",
    "            else:\n",
    "                opinion = token.form + \"-\" + dependant.form      # adjective + \"-\" + adverb\n",
    "        elif (dependant.deprel == \"neg\"): # checks if a depndant of the opinion is a negative\n",
    "            isNeg = True\n",
    "        elif ((dependant.deprel == \"conj\" or dependant.deprel == \"ccomp\") and not ignoredWord(dependant)):\n",
    "            # recursively finds additional words to enhance the current opinion or increace the opinionList \n",
    "            orderList += enhancedOpinions(dependant, isNeg)\n",
    "    if (isNeg == True):             #if the opinion is a negative, it appends a prefix of the word \"not\"\n",
    "        opinion = \"not-\" + opinion\n",
    "    opinionList += [opinion]\n",
    "    opinionList += orderList\n",
    "    return opinionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 sentences printed\n"
     ]
    }
   ],
   "source": [
    "#!!!!!!!!!!!!!!---------TESTER SECTION---------!!!!!!!!!!!!!!!!!\n",
    "from sussex_nltk.parse import load_parsed_example_sentences\n",
    "\n",
    "aspect = \"plot\"   # Set this to the aspect token you're interested in\n",
    "save_file_path = \"examples_output.txt\"    # Set this to the location of the file you wish to create/overwrite with the saved output.\n",
    "\n",
    "# Tracking these numbers will allow us to see what proportion of sentences we discovered features in\n",
    "sentences_with_discovered_features = 0  # Number of sentences we discovered features in\n",
    "total_sentences = 0  # Total number of sentences \n",
    "\n",
    "# This is a \"with statement\", it invokes a context manager, which handles the opening and closing of resources (like files)\n",
    "with open(save_file_path, \"w\") as save_file:  # The 'w' says that we want to write to the file\n",
    "    \n",
    "    # Iterate over all the parsed sentences\n",
    "    for parsed_sentence in load_parsed_example_sentences(): #example...() or dvd...(aspect)   !!!!!\n",
    "        \n",
    "        total_sentences += 1  # We've seen another sentence\n",
    "        \n",
    "        opinions = [] # Make a list for holding any opinions we extract in this sentence\n",
    "\n",
    "        # Iterate over each of the aspect tokens in the sentences (in case there is more than one)\n",
    "        for aspect_token in parsed_sentence.get_query_tokens(aspect):\n",
    "            \n",
    "            # Call your opinion extractor\n",
    "            opinions += opinion_extractor(aspect_token, parsed_sentence)\n",
    "        \n",
    "        # If we found any opinions, write to the output file what we know. \n",
    "        # For testing all of the example sentences will be printed\n",
    "            \n",
    "        # Print a separator and the raw unparsed sentence\n",
    "        save_file.write(\"--- Sentence: %s ---\\n\" % parsed_sentence.raw())  # \"\\n\" starts a new line\n",
    "        # Print the parsed sentence\n",
    "        save_file.write(\"%s\\n\" % parsed_sentence) \n",
    "        # Print opinions extracted\n",
    "        save_file.write(\"Opinions: %s\\n\" % opinions)\n",
    "            \n",
    "        sentences_with_discovered_features += 1  # We've found features in another sentence\n",
    "            \n",
    "print \"%s sentences printed\" % (total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 sentences out of 3119 contained features\n"
     ]
    }
   ],
   "source": [
    "#!!!!!!!!------------Implimented main------------!!!!!!!!!!\n",
    "from sussex_nltk.parse import load_parsed_dvd_sentences\n",
    "\n",
    "aspect = \"plot\"   # Set this to the aspect token you're interested in\n",
    "save_file_path = \"dvd_output.txt\"    # Set this to the location of the file you wish to create/overwrite with the saved output.\n",
    "\n",
    "# Tracking these numbers will allow us to see what proportion of sentences we discovered features in\n",
    "sentences_with_discovered_features = 0  # Number of sentences we discovered features in\n",
    "total_sentences = 0  # Total number of sentences \n",
    "\n",
    "# This is a \"with statement\", it invokes a context manager, which handles the opening and closing of resources (like files)\n",
    "with open(save_file_path, \"w\") as save_file:  # The 'w' says that we want to write to the file\n",
    "    \n",
    "    # Iterate over all the parsed sentences\n",
    "    for parsed_sentence in load_parsed_dvd_sentences(aspect): #example...() or dvd...(aspect)   !!!!!\n",
    "        \n",
    "        total_sentences += 1  # We've seen another sentence\n",
    "        \n",
    "        opinions = [] # Make a list for holding any opinions we extract in this sentence\n",
    "\n",
    "        # Iterate over each of the aspect tokens in the sentences (in case there is more than one)\n",
    "        for aspect_token in parsed_sentence.get_query_tokens(aspect):\n",
    "            \n",
    "            # Call your opinion extractor\n",
    "            opinions += opinion_extractor(aspect_token, parsed_sentence)\n",
    "        \n",
    "        # If we found any opinions, write to the output file what we know.\n",
    "        if opinions: \n",
    "            # Currently, the sentence will only be printed if opinions were found. But if you want to know what you're missing,\n",
    "            # you could move the sentence printing outside the if-statement\n",
    "            \n",
    "            # Print a separator and the raw unparsed sentence\n",
    "            save_file.write(\"--- Sentence: %s ---\\n\" % parsed_sentence.raw())  # \"\\n\" starts a new line\n",
    "            # Print the parsed sentence\n",
    "            save_file.write(\"%s\\n\" % parsed_sentence) \n",
    "            # Print opinions extracted\n",
    "            save_file.write(\"Opinions: %s\\n\" % opinions)\n",
    "            \n",
    "            sentences_with_discovered_features += 1  # We've found features in another sentence\n",
    "            \n",
    "print \"%s sentences out of %s contained features\" % (sentences_with_discovered_features, total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 sentences out of 215 contained features\n"
     ]
    }
   ],
   "source": [
    "#!!!!!!!!------------analysis------------!!!!!!!!!!\n",
    "from sussex_nltk.parse import load_parsed_dvd_sentences\n",
    "\n",
    "aspect = \"plot\"   # Set this to the aspect token you're interested in\n",
    "save_file_path = \"dvd_analysis.txt\"    # Set this to the location of the file you wish to create/overwrite with the saved output.\n",
    "\n",
    "# Tracking these numbers will allow us to see what proportion of sentences we discovered features in\n",
    "sentences_with_discovered_features = 0  # Number of sentences we discovered features in\n",
    "total_sentences = 0  # Total number of sentences \n",
    "\n",
    "# This is a \"with statement\", it invokes a context manager, which handles the opening and closing of resources (like files)\n",
    "with open(save_file_path, \"w\") as save_file:  # The 'w' says that we want to write to the file\n",
    "    \n",
    "    # Iterate over all the parsed sentences\n",
    "    for parsed_sentence in load_parsed_dvd_sentences(aspect): #example...() or dvd...(aspect)   !!!!!\n",
    "        \n",
    "        total_sentences += 1  # We've seen another sentence\n",
    "        \n",
    "        opinions = [] # Make a list for holding any opinions we extract in this sentence\n",
    "\n",
    "        # Iterate over each of the aspect tokens in the sentences (in case there is more than one)\n",
    "        for aspect_token in parsed_sentence.get_query_tokens(aspect):\n",
    "            \n",
    "            # Call your opinion extractor\n",
    "            opinions += opinion_extractor(aspect_token, parsed_sentence)\n",
    "        # If we found any opinions, write to the output file what we know.\n",
    "        if opinions: \n",
    "            # Currently, the sentence will only be printed if opinions were found. But if you want to know what you're missing,\n",
    "            # you could move the sentence printing outside the if-statement\n",
    "            \n",
    "            # Print a separator and the raw unparsed sentence\n",
    "            save_file.write(\"--- Sentence: %s ---\\n\" % parsed_sentence.raw())  # \"\\n\" starts a new line\n",
    "            # Print the parsed sentence\n",
    "            save_file.write(\"%s\\n\" % parsed_sentence) \n",
    "            # Print opinions extracted\n",
    "            save_file.write(\"Opinions: %s\\n\" % opinions)\n",
    "            \n",
    "            sentences_with_discovered_features += 1  # We've found features in another sentence\n",
    "        if sentences_with_discovered_features >= 50:\n",
    "            break\n",
    "            \n",
    "print \"%s sentences out of %s contained features\" % (sentences_with_discovered_features, total_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Proof of Functionality <a id=\"chapter-3\"></a>\n",
    "The writer followed a given list of extensions to build the opinion extractor, as stated in the introduction. The first extension created the original functionality to make the extractor perform some function, and then each following extension asked for additional functionality to be added to the extractor to increase its overall effectiveness.\n",
    "\n",
    "Extensions 1 and 2 created the initial <i>opinion_extractor()</i> function, whilst extensions 3-5 refined the code to improve upon the results or to increase the value of the opinions produced. The author chose to impliment a simple extractor function and then built a more complicated <i>enhancedOpinions()</i> function, which was created from the instructions within extensions 3-5 and then modified to refine the opinions further.\n",
    "\n",
    "Results for this section can be achieved by running the cell marked as the tester section and will be output in the “examples_output.txt” file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.\tExtension 1 <a id=\"chapter-3.1\"></a>\n",
    "Extension 1 looks at adjectival modification and asked the author to: \n",
    "<blockquote><p><i>“Write a version of the opinion extraction function which, when given sentences such as the example below containing an aspects token (e.g. \"plot\"), uses the \"amod\" relations to extract a list of the adjectival modifiers of the aspect token (e.g. the two words \"exciting\" and \"fresh\" in this case).<br/>\n",
    "•\t\"It has an exciting fresh plot.\" produces \"fresh\", \"exciting\"</i></p>\n",
    "</blockquote>\n",
    "In the opinion_extractor method the handling for this is a for loop that checks the “deprel” attribute of the dependants of the aspect token for “amod”. As we’re looking for adjectival modification I also limited the search to only include words tagged as “JJ” (meaning adjective) by the Part-of-Speech (PoS) attribute, as seen in the snippet below.\n",
    "``` python\n",
    "for dependant in parsed_sentence.get_dependants(aspect_token):\n",
    "    if (dependant.deprel == \"amod\" and dependant.pos == \"JJ\"):\n",
    "        opinions += dependant.form\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Extension 2 <a id=\"chapter-3.2\"></a>\n",
    "Extension 2 looks at adjectives linked by couplae. It discusses the relationship between the aspect and the opinion, explaining that in the following example the aspect’s relation is marked as “nsubj” meaning it is a nominal subject. It then asks the writer to:\n",
    "<blockquote><p><i>\n",
    "Your opinion extraction function when given a sentence like the example below containing the aspect token \"plot\", should use appropriate dependency relations to output the term opinion word \"dull\".<br/>\n",
    "•\t\"The plot was dull.\" produces \"dull\"\n",
    "</i></p></blockquote>\n",
    "To ensure that this opinion could be found the writer had to consider the relationship between the opinion and the aspect. As the aspect is then a dependant of the opinion, the route taken was to check if the aspect’s <i>deprel</i> is “nsubj” and then grab the head token, check to see if it is an adjective and if so add it to the list of opinions, as seen in the code snippet below.\n",
    "\n",
    "``` python\n",
    "if(aspect_token.deprel == \"nsubj\"):\n",
    "    head = parsed_sentence.get_head(aspect_token)\n",
    "    if(head.pos == \"JJ\"):\n",
    "        opinions += head.form\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Extensions 3 - 5  <a id=\"chapter-3.3\"></a>\n",
    "Extension 3 and 4 asked the author to refine the quality of the opinions being output. 3 looked to add modifying adverbs by hyphen to the core opinion.\n",
    "<blockquote><p><i>\n",
    "Your opinion extraction function when given a sentence like those below containing the aspect token \"plot\", should use the advmod relation to output features like \"excessively-dull\" (if you have an adjective token in a variable adj_token, and an adverb in a variable adv_token then you could create this feature like this: adv_token.form + \"-\" + adj_token.form).\n",
    "<ul><li>\"It has an excessively dull plot.\" produces \"excessively-dull\"</li>\n",
    "<li>\"The plot was excessively dull.\" produces \"excessively-dull\"</li></ul>\n",
    "</i></p></blockquote>\n",
    "Extension 4 then allowed for the inclusion of negatively modifying words. If the word not (or a parsed “n’t”) appeared in relation to the opinion then the word not is affixed to the front of the opinion.\n",
    "<blockquote><p><i>\n",
    "Your opinion extraction function when given sentences like those below containing the aspect token \"plot\", should use the \"neg\" relation to output features like \"not-dull\". If you have an adjective token called \"token\", then you could create this feature like this: \"not-\" + token.form.<br>\n",
    "adverb in a variable adv_token then you could create this feature like this: adv_token.form + \"-\" + adj_token.form).\n",
    "<ul><li>\"The plot wasn't dull.\" produces \"not-dull\"</li>\n",
    "<li>\"It wasn't an exciting fresh plot.\" produces \"not-exciting\", \"not-fresh\"</li><li>\"The plot wasn't excessively dull.\" produces \"not-excessively-dull\"</li></ul>\n",
    "</i></p></blockquote>\n",
    "Finally, the 5th extension looked at conjunction. This allowed for the extractor to check for words that also expressed opinion, but weren’t directly tied to the aspect. This looked at conjunctives attached to an opinion via the “conj” deprel.\n",
    "<blockquote><p><i>\n",
    "Your opinion extraction function when given sentences like these containing the aspect token \"plot\" should uses the \"conj\" relation to extract all of the relevant features \"cheesy, fun, inspiring\".\n",
    "adverb in a variable adv_token then you could create this feature like this: adv_token.form + \"-\" + adj_token.form).\n",
    "<ul><li>\"The plot was cheesy, but fun and inspiring.\" produces \"cheesy\", \"fun\", \"inspiring\"</li>\n",
    "<li>\"The plot was really cheesy and not particularly special.\" produces \"really-cheesy\", \"not-particularly-special\"</li></ul>\n",
    "</i></p></blockquote>\n",
    "These extensions were all implemented into constructing the *enhancedOpinions()* function. This function checks all the dependants of a given token, checks for *advmods* and *negs*, to modify the opinion accordingly. Next the function checks for *conjs* to see if there should be additional opinions listed and recursively calls itself to see if those opinions need modifying or even if there are more dependant opinions of the current conjunctive. Lastly the function returns all the opinions (modified or no) to the function call (which then adds the list to the current instance of the “opinions” list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the opinion extractor is tasked to run on a list of Amazon DVD reviews the results differ from the pre-selected examples from the extensions and we see how it reacts to varied and differently structured sentences.\n",
    "In its current iteration, this opinion extractor fails 5 of the 16 listed example sentences, meaning that it is likely to miss opinions or flag certain opinions incorrectly. There isn’t an implemented method to connect opinions that require multiple words to form the opinion, (such as the example “full of holes”) nor is there a method to check if the word preceding an opinion is the word “no” or any negative that isn’t listed as a “neg” by the dependant relation. Finally, the extractor is also unable to detect sentiment, and so may incorrectly tag a sarcastic opinion as the opposite of the intended opinion.\n",
    "When the extractor is run on the DVD reviews we see the following results:\n",
    "\n",
    "Aspect        | Opinions identified | Sentences with aspect | Success %\n",
    ":------------:|:-------------------:|:---------------------:|:--------:\n",
    "Plot          | 720                 | 3119                  | 23.1%\n",
    "Characters    | 1303                | 4584                  | 28.4%\n",
    "Cinematography| 285                 | 677                   | 42.1%\n",
    "Dialogue      | 381                 | 1176                  | 32.4%\n",
    "\n",
    "These results show the extractor will on average, find opinions for a given sentence with the assessed aspect 31.5% of the time. In practice this can be as low as 23.1% to a high of 42.1% accuracy, giving a range of 19%, (or ±9.5%).\n",
    "Using the small example selection, the writer assumes that the extractor will miss the opinions of 12.5% (2 in 16) of all sentences. Following this, taking a random selection of 50 sentences from the “plot” aspect analysis can be taken of the sentences that are marked as having an opinion found and untagged results can be ignored. While this is not as accurate as taking a selection of all sentences marked with the plot attribute it allows for sentences that contain no opinion at all to be ignored as well.\n",
    "\n",
    "Out of 50 sampled results, 22 contained incorrectly tagged results, 4 contained ambiguous results and 3 contained at least 1 correct result but missed other opinions. 24 of the results were completely correct. This is a success rate of at least 48% utilising the current data, although this increases to 52% if the ambiguous results are omitted.\n",
    "Some of the incorrect returned results occurred because of incorrect tagging via the parser or PoS tagger e.g. result 40 returned the root of the sentence as “.” Which is not a word and therefore should not be the root of the sentence. This lead to it being incorrectly returned as an opinion. Another example of this is in result 21 where the word interesting was marked as the head being a “(“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
